name: iot-stream-analytics

services:
  # simulate edge devices sending data to the system
  datagen:
    image: docker.io/emqx/mqttx-cli:v1.9.7
    command: mqttx simulate --hostname emqx -f /tmp/datagen.js -pf json -t example -c 3 -im 2500
    volumes:
      - ./datagen.js:/tmp/datagen.js
    depends_on:
      emqx:
        condition: service_healthy
      ksqldb:
        condition: service_healthy

  # mqtt as lightweight message broker, for edge devices
  emqx:
    image: docker.io/library/emqx:5.3.1
    healthcheck:
      test: emqx_ctl status | grep -q 'is started'

  # pool of connect workers to ingest and export data,
  # from and to other systems
  connect:
    build:
      context: ./build/
      target: connect
    deploy:
      replicas: 2
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./vendor:/opt/kafka/plugins/vendor
    healthcheck:
      test: curl -fs http://localhost:8083/connectors || exit 1
    depends_on:
      kafka:
        condition: service_healthy
      # not required but helps to reduce backpreassurre duren startup
      schema-registry:
        condition: service_healthy

  # the central message broker, backing the other services
  kafka:
    build: ./build/
    healthcheck:
      test: kafka-topics.sh --bootstrap-server kafka:9092 --list || exit 1
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092

  # allows to store and retrieve schemas for the data
  schema-registry:
    image: docker.io/confluentinc/cp-schema-registry:7.5.0
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    healthcheck:
      test: curl -fs http://localhost:8081/config || exit 1
    depends_on:
      kafka:
        condition: service_healthy

  # stream processing engine, to manipulate the data as
  # it flows through the system
  ksqldb:
    image: docker.io/confluentinc/ksqldb-server:0.29.0
    environment:
      KSQL_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    healthcheck:
      test:  wget -qO - http://localhost:8088 || exit 1
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      connect:
        condition: service_healthy

  # the migration configures the system, by creating topics,
  # schemas, connectors, and ksql queries.
  # this is because the system is loosely coupled, and
  # can be deployed in different ways, depending on the
  # requirements.
  migration:
    build: ./migration/build/
    entrypoint: migration/migrate.sh
    environment:
      KAFKA_BOOTSTRAP_SERVER: kafka:9092
      KAFKA_NETCLI: kafka:7777
      CONNECT_URL: http://connect:8083
      KSQL_URL: http://ksqldb:8088
      MINIO_URL: http://minio:9000
    volumes:
      - ./migration:/migration
    depends_on:
      kafka:
        condition: service_healthy
      connect:
        condition: service_healthy
      ksqldb:
        condition: service_healthy
      minio:
        condition: service_started
      emqx:
        condition: service_healthy

  # s3 storage to store the data as compressed parquet.
  # Note that this is done by a connect worker
  minio:
    image: quay.io/minio/minio:RELEASE.2023-12-14T18-51-57Z
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    ports:
      - 127.0.0.1:9000:9000 # s3 api
      - 127.0.0.1:9001:9001 # web ui
